name: Deploy GCP Dataproc CI

on:
  pull_request:
    branches: [main]

jobs:
  Dataproc:
    name: Instalar, Construir, Publicar y Desplegar
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        name: Verificar repositorio

      # Instalar Java JDK versión 11
      - name: Instalar JDK 11
        uses: actions/setup-java@v2
        with:
          java-version: "11"
          distribution: "temurin"

      # Iniciar Test, Compilación y Empaquetado
      # - name: Iniciar test
      #   run: sbt test
      - name: Iniciar compilación
        run: sbt compile
      - name: Iniciar empaquetado
        run: sbt package
      # Instalar Credenciales CLI de Google Cloud Platform

      - id: "auth"
        name: "Establecer credenciales gcloud"
        uses: "google-github-actions/auth@v0"
        with:
          credentials_json: "${{ secrets.GCP_CREDENTIALS }}"

      - name: Instalar GCP cli
        uses: google-github-actions/setup-gcloud@v0

      - uses: actions-hub/gcloud@master
        name: Enviar archivo Jar a Datastorage
        env:
          PROJECT_ID: ${{ secrets.GCP_PROJECT }}
          APPLICATION_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}
        with:
          args: cp target/scala-2.12/proyecto_test_2.12-0.1.jar gs://dataproc-test-bdb/
          cli: gsutil

      - uses: actions-hub/gcloud@master
        name: Crear cluster Dataproc
        env:
          PROJECT_ID: ${{ secrets.GCP_PROJECT }}
          APPLICATION_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}
        with:
          args: dataproc clusters create ${{ secrets.GCP_CLUSTER_NAME }} --region ${{ secrets.GCP_REGION }} --subnet default --zone ${{ secrets.GCP_REGION }}-f --single-node --master-machine-type n1-standard-2 --master-boot-disk-size 500 --image-version 2.0-ubuntu18 --optional-components JUPYTER,ZEPPELIN,DOCKER --project ${{ secrets.GCP_PROJECT }}

      - uses: actions-hub/gcloud@master
        name: Enviar Datastorage a jobs dataproc
        env:
          PROJECT_ID: ${{ secrets.GCP_PROJECT }}
          APPLICATION_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}
        with:
          args: dataproc jobs -submit spark --cluster=${{ secrets.GCP_CLUSTER_NAME }} --region=${{ secrets.GCP_REGION }} --jar=gs://dataproc-test-bdb/proyecto_test_2.12-0.1.jar
  Delete-Instance:
    if: always()
    runs-on: ubuntu-latest
    name: Eliminar
    steps:
      - uses: actions/checkout@v2
        name: Verificar repositorio

      - id: "auth"
        name: "Establecer credenciales gcloud"
        uses: "google-github-actions/auth@v0"
        with:
          credentials_json: "${{ secrets.GCP_CREDENTIALS }}"

      - name: Instalar GCP cli
        uses: google-github-actions/setup-gcloud@v0

      - uses: actions-hub/gcloud@master
        name: Eliminar archivo Jar en Datastorage
        env:
          PROJECT_ID: ${{ secrets.GCP_PROJECT }}
          APPLICATION_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}
        with:
          args: rm gs://dataproc-test-bdb/proyecto_test_2.12-0.1.jar
          cli: gsutil

      - uses: actions-hub/gcloud@master
        name: Eliminar cluster
        env:
          PROJECT_ID: ${{ secrets.GCP_PROJECT }}
          APPLICATION_CREDENTIALS: ${{ secrets.GCP_CREDENTIALS }}
        with:
          args: dataproc clusters delete ${{ secrets.GCP_CLUSTER_NAME }} --region ${{ secrets.GCP_REGION }}
